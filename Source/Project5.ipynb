{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Purpose of the Notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem Statement"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Module Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-12-03T22:57:15.348371Z",
     "iopub.status.busy": "2020-12-03T22:57:15.348064Z",
     "iopub.status.idle": "2020-12-03T22:57:15.357645Z",
     "shell.execute_reply": "2020-12-03T22:57:15.356970Z",
     "shell.execute_reply.started": "2020-12-03T22:57:15.348334Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "#os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\" \n",
    "#os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"\"\n",
    "import datetime\n",
    "from collections import Counter\n",
    "import pickle\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import re\n",
    "\n",
    "#to speed up pandas operands\n",
    "from pandarallel import pandarallel\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import nltk\n",
    "from nltk.corpus import wordnet\n",
    "from nltk.tag import pos_tag\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "import keras\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.layers import Embedding, LSTM, Dense\n",
    "from keras.layers import Dense, Dropout, Bidirectional\n",
    "from keras.layers import GlobalAveragePooling1D, Flatten, Conv1D\n",
    "from keras.layers import MaxPooling1D, GlobalMaxPooling1D\n",
    "\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.models import Sequential\n",
    "from keras.optimizers import Adam\n",
    "from keras import regularizers\n",
    "\n",
    "import keras.utils as ku \n",
    "\n",
    "\n",
    "from project5_utils import my_print\n",
    "from project5_utils import my_wait\n",
    "\n",
    "from MyMovieReview import MovieReview\n",
    "from MyMovieReview import MovieReviewGenerator\n",
    "\n",
    "from mymovie import Movie"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-12-03T22:57:15.359086Z",
     "iopub.status.busy": "2020-12-03T22:57:15.358871Z",
     "iopub.status.idle": "2020-12-03T22:57:15.377653Z",
     "shell.execute_reply": "2020-12-03T22:57:15.376860Z",
     "shell.execute_reply.started": "2020-12-03T22:57:15.359058Z"
    }
   },
   "outputs": [],
   "source": [
    "%matplotlib inline "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-12-03T22:57:15.379658Z",
     "iopub.status.busy": "2020-12-03T22:57:15.379372Z",
     "iopub.status.idle": "2020-12-03T22:57:15.398917Z",
     "shell.execute_reply": "2020-12-03T22:57:15.398127Z",
     "shell.execute_reply.started": "2020-12-03T22:57:15.379626Z"
    }
   },
   "outputs": [],
   "source": [
    "LOG_FILE = open(\"../Data/notebook.log\",\"w\")\n",
    "DEBUG = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-12-03T22:57:15.400280Z",
     "iopub.status.busy": "2020-12-03T22:57:15.400114Z",
     "iopub.status.idle": "2020-12-03T22:57:15.405197Z",
     "shell.execute_reply": "2020-12-03T22:57:15.404571Z",
     "shell.execute_reply.started": "2020-12-03T22:57:15.400260Z"
    }
   },
   "outputs": [],
   "source": [
    "#Setting these for now will adjust them\n",
    "VOCAB_SIZE = 400000\n",
    "EMBEDDING_DIM = 300\n",
    "\n",
    "#will calc this based on training set\n",
    "#MAX_LENGTH = 1000\n",
    "TRUC_TYPE = \"post\"\n",
    "PAD_TYPE = \"post\"\n",
    "#Out of Value Token -- or token to indicate a \n",
    "OOV_TOK = \"<OOV>\"\n",
    "\n",
    "TRAIN_SET_PERCENT =  90.0\n",
    "EPOCHS = 100\n",
    "RANDOM_STATE = 42\n",
    "\n",
    "BATCH_SIZE = 96"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-30T18:12:30.876888Z",
     "iopub.status.busy": "2020-11-30T18:12:30.876581Z",
     "iopub.status.idle": "2020-11-30T18:12:30.880535Z",
     "shell.execute_reply": "2020-11-30T18:12:30.879833Z",
     "shell.execute_reply.started": "2020-11-30T18:12:30.876808Z"
    }
   },
   "source": [
    "# Data Processing\n",
    "Get reviews from PKL files into format that can be tokenized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-12-03T22:57:15.406149Z",
     "iopub.status.busy": "2020-12-03T22:57:15.405993Z",
     "iopub.status.idle": "2020-12-03T22:57:15.996130Z",
     "shell.execute_reply": "2020-12-03T22:57:15.995459Z",
     "shell.execute_reply.started": "2020-12-03T22:57:15.406129Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of movie reviews read: 35404\n"
     ]
    }
   ],
   "source": [
    "MOVIE_REVIEWS_PKL_FILE = open(\"../Data/Reviews_back7.pkl\",\"rb\")\n",
    "\n",
    "list_of_movie_reviews = []\n",
    "\n",
    "while 1:\n",
    "    try:\n",
    "        temp_review = pickle.load(MOVIE_REVIEWS_PKL_FILE)\n",
    "        list_of_movie_reviews.append(temp_review)\n",
    "        my_print(\"added this review to the list ==>\\n{}\\n\".format(temp_review), DEBUG, LOG_FILE)\n",
    "    except EOFError:\n",
    "        my_print(\"DONE reading movie reviews\", DEBUG, LOG_FILE)\n",
    "        break\n",
    "        \n",
    "MOVIE_REVIEWS_PKL_FILE.close()\n",
    "print(\"Number of movie reviews read: {}\".format(len(list_of_movie_reviews)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-12-03T22:57:15.997070Z",
     "iopub.status.busy": "2020-12-03T22:57:15.996909Z",
     "iopub.status.idle": "2020-12-03T22:57:16.000070Z",
     "shell.execute_reply": "2020-12-03T22:57:15.999374Z",
     "shell.execute_reply.started": "2020-12-03T22:57:15.997049Z"
    }
   },
   "outputs": [],
   "source": [
    "col_names = list(list_of_movie_reviews[0].__dict__.keys())\n",
    "#col_values = list(list_of_movie_reviews[0].__dict__.values()) --> TODO: REMOVE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-12-03T22:57:16.001009Z",
     "iopub.status.busy": "2020-12-03T22:57:16.000860Z",
     "iopub.status.idle": "2020-12-03T22:57:16.152683Z",
     "shell.execute_reply": "2020-12-03T22:57:16.152062Z",
     "shell.execute_reply.started": "2020-12-03T22:57:16.000990Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review_text</th>\n",
       "      <th>review_star_rating</th>\n",
       "      <th>reviewer_name</th>\n",
       "      <th>directlink_url</th>\n",
       "      <th>reviewlink_url</th>\n",
       "      <th>title</th>\n",
       "      <th>review_title</th>\n",
       "      <th>review_date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>At the end of this movie there's a shot of the...</td>\n",
       "      <td>2</td>\n",
       "      <td>veardleyw</td>\n",
       "      <td>http://www.imdb.com/title/tt4669788/</td>\n",
       "      <td>http://www.imdb.com/review/rw4675276/</td>\n",
       "      <td>On the Basis of Sex</td>\n",
       "      <td>Feeble, telemovie-style travesty of a potentia...</td>\n",
       "      <td>20 February 2019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>The film starts in 1956 with RBG (Felicity Jon...</td>\n",
       "      <td>8</td>\n",
       "      <td>nogodnomasters</td>\n",
       "      <td>http://www.imdb.com/title/tt4669788/</td>\n",
       "      <td>http://www.imdb.com/review/rw4783407/</td>\n",
       "      <td>On the Basis of Sex</td>\n",
       "      <td>It's not a movement if everyone is just sitting.</td>\n",
       "      <td>15 April 2019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>This well meaning movie shows the discriminati...</td>\n",
       "      <td>5</td>\n",
       "      <td>phd_travel</td>\n",
       "      <td>http://www.imdb.com/title/tt4669788/</td>\n",
       "      <td>http://www.imdb.com/review/rw4590175/</td>\n",
       "      <td>On the Basis of Sex</td>\n",
       "      <td>Well intentioned but miscast</td>\n",
       "      <td>18 January 2019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Why would you make a movie about the second fe...</td>\n",
       "      <td>1</td>\n",
       "      <td>Viking131313</td>\n",
       "      <td>http://www.imdb.com/title/tt4669788/</td>\n",
       "      <td>http://www.imdb.com/review/rw4621289/</td>\n",
       "      <td>On the Basis of Sex</td>\n",
       "      <td>Makes no sense.</td>\n",
       "      <td>2 February 2019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>This movie was very well done. Good acting and...</td>\n",
       "      <td>10</td>\n",
       "      <td>MikeChm</td>\n",
       "      <td>http://www.imdb.com/title/tt4669788/</td>\n",
       "      <td>http://www.imdb.com/review/rw4583636/</td>\n",
       "      <td>On the Basis of Sex</td>\n",
       "      <td>Well worth going to see!</td>\n",
       "      <td>15 January 2019</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         review_text  review_star_rating  \\\n",
       "0  At the end of this movie there's a shot of the...                   2   \n",
       "1  The film starts in 1956 with RBG (Felicity Jon...                   8   \n",
       "2  This well meaning movie shows the discriminati...                   5   \n",
       "3  Why would you make a movie about the second fe...                   1   \n",
       "4  This movie was very well done. Good acting and...                  10   \n",
       "\n",
       "    reviewer_name                        directlink_url  \\\n",
       "0       veardleyw  http://www.imdb.com/title/tt4669788/   \n",
       "1  nogodnomasters  http://www.imdb.com/title/tt4669788/   \n",
       "2      phd_travel  http://www.imdb.com/title/tt4669788/   \n",
       "3    Viking131313  http://www.imdb.com/title/tt4669788/   \n",
       "4         MikeChm  http://www.imdb.com/title/tt4669788/   \n",
       "\n",
       "                          reviewlink_url                title  \\\n",
       "0  http://www.imdb.com/review/rw4675276/  On the Basis of Sex   \n",
       "1  http://www.imdb.com/review/rw4783407/  On the Basis of Sex   \n",
       "2  http://www.imdb.com/review/rw4590175/  On the Basis of Sex   \n",
       "3  http://www.imdb.com/review/rw4621289/  On the Basis of Sex   \n",
       "4  http://www.imdb.com/review/rw4583636/  On the Basis of Sex   \n",
       "\n",
       "                                        review_title       review_date  \n",
       "0  Feeble, telemovie-style travesty of a potentia...  20 February 2019  \n",
       "1   It's not a movement if everyone is just sitting.     15 April 2019  \n",
       "2                       Well intentioned but miscast   18 January 2019  \n",
       "3                                    Makes no sense.   2 February 2019  \n",
       "4                           Well worth going to see!   15 January 2019  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list_of_movie_review_lists = []\n",
    "\n",
    "for review_col_name in col_names:\n",
    "    list_of_movie_review_data_vals = []\n",
    "    \n",
    "    for review_obj in list_of_movie_reviews:\n",
    "        list_of_movie_review_data_vals.append ( review_obj.__dict__[review_col_name] )\n",
    "        \n",
    "    list_of_movie_review_lists.append(list_of_movie_review_data_vals)\n",
    "    \n",
    "reviews_dict = dict(zip(col_names,list_of_movie_review_lists))\n",
    "reviews_df = pd.DataFrame(reviews_dict)\n",
    "reviews_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**QUICK AND DIRTY CLEANING**\n",
    "\n",
    "TODO: Go back and Improve it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-12-03T22:57:16.153543Z",
     "iopub.status.busy": "2020-12-03T22:57:16.153391Z",
     "iopub.status.idle": "2020-12-03T22:57:16.285942Z",
     "shell.execute_reply": "2020-12-03T22:57:16.285287Z",
     "shell.execute_reply.started": "2020-12-03T22:57:16.153523Z"
    }
   },
   "outputs": [],
   "source": [
    "#Get rid of instances of people spamming the same review\n",
    "reviews_df.drop_duplicates(subset=[\"review_text\"],keep=\"first\",inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-12-03T22:57:16.287624Z",
     "iopub.status.busy": "2020-12-03T22:57:16.287465Z",
     "iopub.status.idle": "2020-12-03T22:57:16.296954Z",
     "shell.execute_reply": "2020-12-03T22:57:16.296307Z",
     "shell.execute_reply.started": "2020-12-03T22:57:16.287604Z"
    }
   },
   "outputs": [],
   "source": [
    "#Get rid of reviews where \"review_star_rating\" is missing or \"review_text\" is missing\n",
    "mask = (reviews_df[\"review_text\"] == \"EMPTY\") | (reviews_df[\"review_star_rating\"] == -1)\n",
    "mask_keep = ~mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-12-03T22:57:16.297967Z",
     "iopub.status.busy": "2020-12-03T22:57:16.297809Z",
     "iopub.status.idle": "2020-12-03T22:57:16.317555Z",
     "shell.execute_reply": "2020-12-03T22:57:16.316926Z",
     "shell.execute_reply.started": "2020-12-03T22:57:16.297940Z"
    }
   },
   "outputs": [],
   "source": [
    "reviews_df = reviews_df[mask_keep]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-12-03T22:57:16.318452Z",
     "iopub.status.busy": "2020-12-03T22:57:16.318304Z",
     "iopub.status.idle": "2020-12-03T22:57:16.360273Z",
     "shell.execute_reply": "2020-12-03T22:57:16.359632Z",
     "shell.execute_reply.started": "2020-12-03T22:57:16.318432Z"
    }
   },
   "outputs": [],
   "source": [
    "reviews_df.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-12-03T22:57:16.361176Z",
     "iopub.status.busy": "2020-12-03T22:57:16.361027Z",
     "iopub.status.idle": "2020-12-03T22:57:16.366723Z",
     "shell.execute_reply": "2020-12-03T22:57:16.366160Z",
     "shell.execute_reply.started": "2020-12-03T22:57:16.361156Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(35342, 8)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reviews_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-12-03T22:57:16.367431Z",
     "iopub.status.busy": "2020-12-03T22:57:16.367282Z",
     "iopub.status.idle": "2020-12-03T22:57:16.379981Z",
     "shell.execute_reply": "2020-12-03T22:57:16.379216Z",
     "shell.execute_reply.started": "2020-12-03T22:57:16.367412Z"
    }
   },
   "outputs": [],
   "source": [
    "text_of_reviews = reviews_df[[\"review_title\",\"review_text\",\"review_star_rating\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Text corpus will be composed of the review title concatenated with the review text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-12-03T22:57:16.381165Z",
     "iopub.status.busy": "2020-12-03T22:57:16.380939Z",
     "iopub.status.idle": "2020-12-03T22:57:16.429350Z",
     "shell.execute_reply": "2020-12-03T22:57:16.428713Z",
     "shell.execute_reply.started": "2020-12-03T22:57:16.381136Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-34-b4d769d80be9>:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  text_of_reviews[\"review_observation\"] = text_of_reviews[\"review_title\"] + \" \" + text_of_reviews[\"review_text\"]\n"
     ]
    }
   ],
   "source": [
    "text_of_reviews[\"review_observation\"] = text_of_reviews[\"review_title\"] + \" \" + text_of_reviews[\"review_text\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-12-03T22:57:16.430233Z",
     "iopub.status.busy": "2020-12-03T22:57:16.430083Z",
     "iopub.status.idle": "2020-12-03T22:57:16.440697Z",
     "shell.execute_reply": "2020-12-03T22:57:16.440030Z",
     "shell.execute_reply.started": "2020-12-03T22:57:16.430213Z"
    }
   },
   "outputs": [],
   "source": [
    "text_of_reviews = text_of_reviews.drop([\"review_title\",\"review_text\"], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-12-03T22:57:21.434430Z",
     "iopub.status.busy": "2020-12-03T22:57:21.434179Z",
     "iopub.status.idle": "2020-12-03T22:57:21.439466Z",
     "shell.execute_reply": "2020-12-03T22:57:21.438728Z",
     "shell.execute_reply.started": "2020-12-03T22:57:21.434402Z"
    }
   },
   "outputs": [],
   "source": [
    "text_of_reviews = text_of_reviews.rename(columns= {\"review_observation\":\"review_text\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-12-03T22:57:22.167300Z",
     "iopub.status.busy": "2020-12-03T22:57:22.167045Z",
     "iopub.status.idle": "2020-12-03T22:57:22.175577Z",
     "shell.execute_reply": "2020-12-03T22:57:22.174934Z",
     "shell.execute_reply.started": "2020-12-03T22:57:22.167271Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review_star_rating</th>\n",
       "      <th>review_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>Feeble, telemovie-style travesty of a potentia...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8</td>\n",
       "      <td>It's not a movement if everyone is just sittin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>Well intentioned but miscast This well meaning...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>Makes no sense. Why would you make a movie abo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10</td>\n",
       "      <td>Well worth going to see! This movie was very w...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   review_star_rating                                        review_text\n",
       "0                   2  Feeble, telemovie-style travesty of a potentia...\n",
       "1                   8  It's not a movement if everyone is just sittin...\n",
       "2                   5  Well intentioned but miscast This well meaning...\n",
       "3                   1  Makes no sense. Why would you make a movie abo...\n",
       "4                  10  Well worth going to see! This movie was very w..."
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_of_reviews.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**TODO:** Do Some stats\n",
    "\n",
    "* Are the classes balanced?\n",
    "* What's the mean, mode, stddev of the classes?\n",
    "* Length of reviews: mean, mode, std dev, and all of this for each class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-12-03T22:57:23.626956Z",
     "iopub.status.busy": "2020-12-03T22:57:23.626705Z",
     "iopub.status.idle": "2020-12-03T22:57:23.631135Z",
     "shell.execute_reply": "2020-12-03T22:57:23.630500Z",
     "shell.execute_reply.started": "2020-12-03T22:57:23.626928Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "35342"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(text_of_reviews)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleaning and Lemmatization\n",
    "To reduce dimentionality of the corpus\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-12-03T22:57:24.832596Z",
     "iopub.status.busy": "2020-12-03T22:57:24.832343Z",
     "iopub.status.idle": "2020-12-03T22:57:24.838358Z",
     "shell.execute_reply": "2020-12-03T22:57:24.837647Z",
     "shell.execute_reply.started": "2020-12-03T22:57:24.832567Z"
    }
   },
   "outputs": [],
   "source": [
    "def remove_html_punct(row):\n",
    "    \"\"\"This function removes HTML and punctuation and anything that is or contains a number from the Text\"\"\"\n",
    "    \n",
    "    NLTK_WORDS = set(nltk.corpus.words.words())\n",
    "    \n",
    "    text_to_process = row[\"review_text\"]\n",
    "    text_to_process = text_to_process.lower()\n",
    "    text_to_process = re.sub(\"<.*?>\",\"\",text_to_process)\n",
    "    text_to_process = re.sub(\"[\\.|\\!|\\?|\\,|\\;|\\:|\\&|\\(|\\)|\\-|\\%|_|\\#|\\$|\\*|\\+|\\/|\\=|\\[|\\]|\\^|\\`|\\{|\\}|\\~]\",\"\",text_to_process)\n",
    "    text_to_process = re.sub(\"\\w*\\d+\\w*\",\"\",text_to_process)\n",
    "    text_to_process_list = text_to_process.split()\n",
    "    text_to_process_list = [review_word for review_word in text_to_process_list if review_word in NLTK_WORDS]\n",
    "    text_to_process = \" \".join(text_to_process_list)\n",
    "    return text_to_process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-12-03T22:57:26.699692Z",
     "iopub.status.busy": "2020-12-03T22:57:26.699424Z",
     "iopub.status.idle": "2020-12-03T23:04:03.906789Z",
     "shell.execute_reply": "2020-12-03T23:04:03.906027Z",
     "shell.execute_reply.started": "2020-12-03T22:57:26.699664Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO: Pandarallel will run on 64 workers.\n",
      "INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.\n",
      "time spent doing operation is 0:06:37.201333\n"
     ]
    }
   ],
   "source": [
    "pandarallel.initialize()\n",
    "start_time = datetime.datetime.now()\n",
    "\n",
    "text_of_reviews[\"review_text\"] = text_of_reviews.parallel_apply(remove_html_punct, axis=1)\n",
    "\n",
    "end_time = datetime.datetime.now()\n",
    "print(\"time spent doing operation is {}\".format(end_time - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-12-03T23:04:14.603491Z",
     "iopub.status.busy": "2020-12-03T23:04:14.603218Z",
     "iopub.status.idle": "2020-12-03T23:04:14.654356Z",
     "shell.execute_reply": "2020-12-03T23:04:14.653683Z",
     "shell.execute_reply.started": "2020-12-03T23:04:14.603462Z"
    }
   },
   "outputs": [],
   "source": [
    "text_of_reviews[\"review_text\"] = text_of_reviews[\"review_text\"].apply(lambda x : x.lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-12-03T23:04:18.675171Z",
     "iopub.status.busy": "2020-12-03T23:04:18.674895Z",
     "iopub.status.idle": "2020-12-03T23:04:18.679461Z",
     "shell.execute_reply": "2020-12-03T23:04:18.678636Z",
     "shell.execute_reply.started": "2020-12-03T23:04:18.675142Z"
    }
   },
   "outputs": [],
   "source": [
    "def tokenize_text(row):\n",
    "    temp_tokenized_txt = word_tokenize(row[\"review_text\"])\n",
    "    return temp_tokenized_txt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-12-03T23:04:20.017550Z",
     "iopub.status.busy": "2020-12-03T23:04:20.017296Z",
     "iopub.status.idle": "2020-12-03T23:04:23.154387Z",
     "shell.execute_reply": "2020-12-03T23:04:23.153580Z",
     "shell.execute_reply.started": "2020-12-03T23:04:20.017522Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO: Pandarallel will run on 64 workers.\n",
      "INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.\n",
      "time spent doing operation is 0:00:03.131240\n"
     ]
    }
   ],
   "source": [
    "pandarallel.initialize()\n",
    "start_time = datetime.datetime.now()\n",
    "\n",
    "text_of_reviews[\"review_text\"] = text_of_reviews.parallel_apply(tokenize_text,axis=1)\n",
    "\n",
    "end_time = datetime.datetime.now()\n",
    "print(\"time spent doing operation is {}\".format(end_time - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-12-03T23:04:31.449039Z",
     "iopub.status.busy": "2020-12-03T23:04:31.448778Z",
     "iopub.status.idle": "2020-12-03T23:04:31.452280Z",
     "shell.execute_reply": "2020-12-03T23:04:31.451612Z",
     "shell.execute_reply.started": "2020-12-03T23:04:31.449010Z"
    }
   },
   "outputs": [],
   "source": [
    "wordNetLemmatizer = WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-12-03T23:04:32.177248Z",
     "iopub.status.busy": "2020-12-03T23:04:32.176994Z",
     "iopub.status.idle": "2020-12-03T23:04:32.181542Z",
     "shell.execute_reply": "2020-12-03T23:04:32.180905Z",
     "shell.execute_reply.started": "2020-12-03T23:04:32.177220Z"
    }
   },
   "outputs": [],
   "source": [
    "def calc_partofspeech(raw_pos):\n",
    "    \"\"\"translates from POS generated by pos_tag() to a POS encoding that WordNetLemmatizer.lemmatize() understands\"\"\"\n",
    "    #print(\"word = \",word)\n",
    "    #[(output_word, output_pos)] = pos_tag(word_tokenize(word))\n",
    "    \n",
    "    #decode output_pos to the pos required by the lemmatizer\n",
    "    \n",
    "    if \"JJ\" in raw_pos:\n",
    "        pos = \"a\"\n",
    "    elif \"RB\" in raw_pos:\n",
    "        pos = \"r\"\n",
    "    elif \"VB\" in raw_pos:\n",
    "        pos = \"v\"\n",
    "    else:\n",
    "        pos = \"n\"\n",
    "    \n",
    "    return pos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-12-03T23:04:37.448058Z",
     "iopub.status.busy": "2020-12-03T23:04:37.447806Z",
     "iopub.status.idle": "2020-12-03T23:04:37.452379Z",
     "shell.execute_reply": "2020-12-03T23:04:37.451732Z",
     "shell.execute_reply.started": "2020-12-03T23:04:37.448030Z"
    }
   },
   "outputs": [],
   "source": [
    "def lemmatize_it(row):\n",
    "    \n",
    "    pos_result = pos_tag(row[\"review_text\"])\n",
    "    \n",
    "    temp_mydoc_lemmatized = []\n",
    "    \n",
    "    for myword,myPOS in pos_result:\n",
    "        temp_word_lemmatized = wordNetLemmatizer.lemmatize(myword,calc_partofspeech(myPOS))\n",
    "        temp_mydoc_lemmatized.append(temp_word_lemmatized)\n",
    "    \n",
    "    return temp_mydoc_lemmatized\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-12-03T23:04:44.776725Z",
     "iopub.status.busy": "2020-12-03T23:04:44.776474Z",
     "iopub.status.idle": "2020-12-03T23:05:17.802974Z",
     "shell.execute_reply": "2020-12-03T23:05:17.802177Z",
     "shell.execute_reply.started": "2020-12-03T23:04:44.776697Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO: Pandarallel will run on 64 workers.\n",
      "INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.\n",
      "time spent doing operation is 0:00:33.020713\n"
     ]
    }
   ],
   "source": [
    "pandarallel.initialize()\n",
    "start_time = datetime.datetime.now()\n",
    "\n",
    "text_of_reviews[\"review_text\"] = text_of_reviews.parallel_apply(lemmatize_it,axis=1)\n",
    "\n",
    "end_time = datetime.datetime.now()\n",
    "print(\"time spent doing operation is {}\".format(end_time - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-12-03T23:05:22.331348Z",
     "iopub.status.busy": "2020-12-03T23:05:22.331048Z",
     "iopub.status.idle": "2020-12-03T23:05:25.215085Z",
     "shell.execute_reply": "2020-12-03T23:05:25.214071Z",
     "shell.execute_reply.started": "2020-12-03T23:05:22.331316Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO: Pandarallel will run on 64 workers.\n",
      "INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.\n",
      "time spent doing operation is 0:00:02.877137\n"
     ]
    }
   ],
   "source": [
    "pandarallel.initialize()\n",
    "start_time = datetime.datetime.now()\n",
    "text_of_reviews[\"review_text\"]  = text_of_reviews.parallel_apply(lambda x : \" \".join(x[\"review_text\"]), axis=1)\n",
    "end_time = datetime.datetime.now()\n",
    "print(\"time spent doing operation is {}\".format(end_time - start_time))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stop word removal\n",
    "Should I do it?\n",
    "\n",
    "It lowers dimensionality which can improve training time.\n",
    "\n",
    "But for a sequence model won't removing the stop words hurt the ability of the model to learn sequences that may be indicative of a specific class? In this project I need pretty high precision because I have 10 categories to classify based on text.\n",
    "\n",
    "Some stuff I've read:\n",
    "\n",
    "**Pro or Con**:\n",
    "\n",
    "* https://stackoverflow.com/questions/37325914/should-i-remove-stopwords-when-feed-sentence-to-rnn\n",
    "* https://www.quora.com/Is-text-preprocessing-e-g-stop-words-removing-still-necessary-in-neural-based-NLP\n",
    "* https://www.quora.com/Is-text-preprocessing-e-g-stop-words-removing-still-necessary-in-neural-based-NLP\n",
    "\n",
    "Reading the last link I think I should keep the stop words. The star rating applied to a reviews is a form of sentiment about the review. If a reviewer says \"I was not happy with the ending of the movie,\" stop word removal may convert that to \"happy movie ending\". This may result in two reviews containing the words \"happy movie ending\": One with a review of 2 and another with a review of 8 with the original text for the latter score being \"I was happy with the ending of the movie.\"\n",
    "\n",
    "So will not do stop word removal for now but will keep in as an option if results seem to call for it.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-12-03T23:05:28.164205Z",
     "iopub.status.busy": "2020-12-03T23:05:28.163930Z",
     "iopub.status.idle": "2020-12-03T23:05:28.173560Z",
     "shell.execute_reply": "2020-12-03T23:05:28.172913Z",
     "shell.execute_reply.started": "2020-12-03T23:05:28.164176Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review_star_rating</th>\n",
       "      <th>review_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>feeble travesty of a potentially fascinating s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8</td>\n",
       "      <td>not a movement if everyone be just sit the fil...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>well intentioned but miscast this well mean mo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>no sense why would you make a movie about the ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10</td>\n",
       "      <td>well worth go to see this movie be very well d...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   review_star_rating                                        review_text\n",
       "0                   2  feeble travesty of a potentially fascinating s...\n",
       "1                   8  not a movement if everyone be just sit the fil...\n",
       "2                   5  well intentioned but miscast this well mean mo...\n",
       "3                   1  no sense why would you make a movie about the ...\n",
       "4                  10  well worth go to see this movie be very well d..."
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_of_reviews.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-12-03T23:05:44.149294Z",
     "iopub.status.busy": "2020-12-03T23:05:44.149036Z",
     "iopub.status.idle": "2020-12-03T23:05:44.153995Z",
     "shell.execute_reply": "2020-12-03T23:05:44.153346Z",
     "shell.execute_reply.started": "2020-12-03T23:05:44.149266Z"
    }
   },
   "outputs": [],
   "source": [
    "#shifting range of ratings from 1,10 to 0,9\n",
    "text_of_reviews[\"review_star_rating\"] = text_of_reviews[\"review_star_rating\"] - 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-12-03T23:05:44.760826Z",
     "iopub.status.busy": "2020-12-03T23:05:44.760571Z",
     "iopub.status.idle": "2020-12-03T23:05:44.765129Z",
     "shell.execute_reply": "2020-12-03T23:05:44.764463Z",
     "shell.execute_reply.started": "2020-12-03T23:05:44.760798Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(35342, 2)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_of_reviews.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-12-03T23:06:05.944228Z",
     "iopub.status.busy": "2020-12-03T23:06:05.943966Z",
     "iopub.status.idle": "2020-12-03T23:06:05.954622Z",
     "shell.execute_reply": "2020-12-03T23:06:05.954017Z",
     "shell.execute_reply.started": "2020-12-03T23:06:05.944200Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "31807\n",
      "(35342, 2)\n",
      "(31807,)\n",
      "(3535,)\n"
     ]
    }
   ],
   "source": [
    "#TODO Randomize sets or find tensorflow train test split or use sklearn train test split\n",
    "train_set_size = int ( ( text_of_reviews.shape[0] * TRAIN_SET_PERCENT ) / 100 )\n",
    "#test_set_size =  text_of_reviews.shape[0] - train_set_size\n",
    "\n",
    "review_indices = np.arange(text_of_reviews.shape[0]) \n",
    "\n",
    "np.random.shuffle( review_indices)\n",
    "\n",
    "\n",
    "text_of_reviews = text_of_reviews.iloc[review_indices]\n",
    "\n",
    "training_indices = review_indices[:train_set_size]\n",
    "testing_indices = review_indices[train_set_size:]\n",
    "\n",
    "\n",
    "print(train_set_size)\n",
    "print(text_of_reviews.shape)\n",
    "print(training_indices.shape)\n",
    "print(testing_indices.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-12-03T23:06:11.985123Z",
     "iopub.status.busy": "2020-12-03T23:06:11.984870Z",
     "iopub.status.idle": "2020-12-03T23:06:11.993701Z",
     "shell.execute_reply": "2020-12-03T23:06:11.993031Z",
     "shell.execute_reply.started": "2020-12-03T23:06:11.985096Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review_star_rating</th>\n",
       "      <th>review_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>25248</th>\n",
       "      <td>5</td>\n",
       "      <td>this a bad movie but not brilliant triple be a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2104</th>\n",
       "      <td>7</td>\n",
       "      <td>best star film by out of all the the i think t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26159</th>\n",
       "      <td>0</td>\n",
       "      <td>total garbage i be a fan of the show i it but ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8704</th>\n",
       "      <td>0</td>\n",
       "      <td>waste your time the bad piece of dirt this yea...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30075</th>\n",
       "      <td>6</td>\n",
       "      <td>a good comedy with a great cast a good old fas...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       review_star_rating                                        review_text\n",
       "25248                   5  this a bad movie but not brilliant triple be a...\n",
       "2104                    7  best star film by out of all the the i think t...\n",
       "26159                   0  total garbage i be a fan of the show i it but ...\n",
       "8704                    0  waste your time the bad piece of dirt this yea...\n",
       "30075                   6  a good comedy with a great cast a good old fas..."
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_of_reviews.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-12-03T23:06:25.433911Z",
     "iopub.status.busy": "2020-12-03T23:06:25.433657Z",
     "iopub.status.idle": "2020-12-03T23:06:25.445204Z",
     "shell.execute_reply": "2020-12-03T23:06:25.444537Z",
     "shell.execute_reply.started": "2020-12-03T23:06:25.433883Z"
    }
   },
   "outputs": [],
   "source": [
    "#spent hours trying to re-implement train_test_split() :*-(\n",
    "\n",
    "#train_new_reviews = text_of_reviews.loc[text_of_reviews.index.intersection(training_indices),\"review_text\"]\n",
    "#train_new_reviews_rating = text_of_reviews.loc[text_of_reviews.index.intersection(training_indices),\"review_star_rating\"]\n",
    "\n",
    "#train_text_reviews = text_of_reviews.sample(n=train_set_size, random_state=RANDOM_STATE, )\n",
    "\n",
    "#test_new_reviews = text_of_reviews.loc[text_of_reviews.index.intersection(testing_indices),\"review_text\"]\n",
    "#test_new_reviews_rating = text_of_reviews.loc[text_of_reviews.index.intersection(testing_indices),\"review_star_rating\"]\n",
    "\n",
    "X = text_of_reviews[\"review_text\"]\n",
    "y = text_of_reviews[\"review_star_rating\"]\n",
    "\n",
    "Test_Size = 1.0 - (TRAIN_SET_PERCENT/100.0)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=Test_Size, random_state=RANDOM_STATE)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-12-03T23:06:28.081885Z",
     "iopub.status.busy": "2020-12-03T23:06:28.081620Z",
     "iopub.status.idle": "2020-12-03T23:06:28.086571Z",
     "shell.execute_reply": "2020-12-03T23:06:28.085874Z",
     "shell.execute_reply.started": "2020-12-03T23:06:28.081857Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(31807,)\n",
      "(31807,)\n",
      "(3535,)\n",
      "(3535,)\n"
     ]
    }
   ],
   "source": [
    "#TODO\n",
    "#Lemmatization\n",
    "#stop word removal\n",
    "print(X_train.shape)\n",
    "print(y_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-12-03T23:07:35.187652Z",
     "iopub.status.busy": "2020-12-03T23:07:35.187384Z",
     "iopub.status.idle": "2020-12-03T23:07:35.203229Z",
     "shell.execute_reply": "2020-12-03T23:07:35.202558Z",
     "shell.execute_reply.started": "2020-12-03T23:07:35.187624Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max_Length = 7779\n"
     ]
    }
   ],
   "source": [
    "Max_Length = max([len(doc) for doc in X_train])\n",
    "print(\"Max_Length = {}\".format(Max_Length))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-12-03T23:09:13.261315Z",
     "iopub.status.busy": "2020-12-03T23:09:13.261060Z",
     "iopub.status.idle": "2020-12-03T23:09:17.149396Z",
     "shell.execute_reply": "2020-12-03T23:09:17.148636Z",
     "shell.execute_reply.started": "2020-12-03T23:09:13.261286Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "word_index[<OOV>] = 1\n",
      "word_index[the] = 2\n",
      "word_index[be] = 3\n",
      "word_index[a] = 4\n",
      "word_index[and] = 5\n",
      "word_index[to] = 6\n",
      "word_index[of] = 7\n",
      "word_index[it] = 8\n",
      "word_index[in] = 9\n",
      "word_index[i] = 10\n",
      "\n",
      "total words is 25515\n"
     ]
    }
   ],
   "source": [
    "tokenizer = Tokenizer(oov_token=OOV_TOK, num_words=VOCAB_SIZE)\n",
    "tokenizer.fit_on_texts(X_train)\n",
    "total_words = len(tokenizer.word_index)+1\n",
    "i = 0\n",
    "for key, value in tokenizer.word_index.items():\n",
    "    \n",
    "    if i == 10:\n",
    "        break\n",
    "        \n",
    "    print(\"word_index[{}] = {}\".format(key, value))\n",
    "    i += 1\n",
    "    \n",
    "print(\"\\ntotal words is {}\".format(total_words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-12-03T23:53:09.578881Z",
     "iopub.status.busy": "2020-12-03T23:53:09.578602Z",
     "iopub.status.idle": "2020-12-03T23:53:16.118437Z",
     "shell.execute_reply": "2020-12-03T23:53:16.117724Z",
     "shell.execute_reply.started": "2020-12-03T23:53:09.578851Z"
    }
   },
   "outputs": [],
   "source": [
    "X_train_seq = tokenizer.texts_to_sequences(X_train)\n",
    "X_train_seq_pad = pad_sequences(X_train_seq, maxlen=Max_Length, padding=PAD_TYPE, truncating=TRUC_TYPE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-12-03T23:53:28.539141Z",
     "iopub.status.busy": "2020-12-03T23:53:28.538881Z",
     "iopub.status.idle": "2020-12-03T23:53:29.180510Z",
     "shell.execute_reply": "2020-12-03T23:53:29.179712Z",
     "shell.execute_reply.started": "2020-12-03T23:53:28.539113Z"
    }
   },
   "outputs": [],
   "source": [
    "X_test_seq = tokenizer.texts_to_sequences(X_test)\n",
    "X_test_seq_pad = pad_sequences(X_test_seq, maxlen=Max_Length, padding=PAD_TYPE, truncating=TRUC_TYPE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-12-03T23:53:35.813422Z",
     "iopub.status.busy": "2020-12-03T23:53:35.813144Z",
     "iopub.status.idle": "2020-12-03T23:53:35.819217Z",
     "shell.execute_reply": "2020-12-03T23:53:35.818548Z",
     "shell.execute_reply.started": "2020-12-03T23:53:35.813394Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "thing = [29, 51, 69, 42, 2793, 72, 12, 2, 2286, 15, 12, 17, 3, 596, 52, 212, 14, 27, 7, 2, 103, 97, 509, 294, 48, 19, 2, 103, 9, 870, 411, 30, 10, 43, 74, 12, 17, 14, 4, 111, 7062, 5, 4, 114, 7, 3147, 10, 64, 547, 82, 11, 10, 3, 19, 683, 12, 3, 4, 212, 6690, 2467, 2793, 140, 628, 8781, 1617, 97, 13, 12, 17, 65, 19, 18, 3, 46, 7, 242, 9, 2, 16, 6, 635, 74, 2, 1626, 7, 870, 97, 304, 8, 3, 482, 69, 42, 1159, 5, 1744, 72, 83, 531, 172, 97, 16, 12, 6, 2, 17, 5, 4, 1904, 7, 1300, 306, 8, 48, 20, 43, 186, 319, 85, 8, 43, 6, 3, 163, 12, 17, 23, 44, 8, 6, 23, 8, 1215, 6, 2299, 628, 5, 473, 15, 2, 1210, 7, 26, 373, 13554, 16, 79, 1142, 486, 98, 25, 83, 7, 2, 85, 37, 63, 54, 12, 17, 448, 58, 54, 2, 383, 97, 7, 2, 5, 5, 3, 149, 155, 15, 4, 171, 7, 106, 3, 19, 11, 153, 16, 8, 179, 6, 3, 669, 3, 8, 6, 3, 2, 138, 43, 169, 82, 3, 354, 44, 93, 18, 3, 4, 973, 7, 8537, 84, 58, 3, 4, 553, 439, 7, 104, 2825, 3, 7587, 5, 180, 216, 89, 987, 3, 57, 620, 27, 6193, 64, 90, 286, 4, 128, 3662, 21, 2, 123, 15, 51, 30, 105, 1643, 1201, 2, 196, 234, 5, 137, 41, 8, 99, 150, 2, 69, 1358, 7, 110, 657, 85, 3, 318, 254, 8, 3, 441, 5, 10, 71, 4, 68, 357, 9, 3, 4, 68, 17, 11, 20, 2341, 6, 101, 863, 880, 20, 4313, 5, 273, 46, 682, 5, 135, 20, 14, 3216, 8, 3, 486, 5, 416, 25, 28, 2, 139, 49, 14, 42, 5, 72, 5, 42, 1733, 72, 1528, 12, 3, 4, 228, 36, 17, 15, 94, 13, 3476, 39, 97, 509, 8, 3, 345, 19, 15, 2, 3916, 2889, 39, 15, 16, 15, 94, 214, 97, 13, 1718, 12, 3, 2, 1537, 6919, 287, 203]\n",
      "thing = [301, 57, 175, 3, 19, 15, 2, 3916, 7, 288, 8, 3, 19, 15, 39, 15, 131, 14, 4, 626, 7441, 628, 5, 841, 526, 3, 19, 2, 928, 2, 473, 3, 192, 1935, 201, 5, 2, 85, 29, 1287, 306, 507, 2082, 359, 48, 29, 1076, 5, 9, 50, 29, 35, 5202, 57, 28, 4, 474, 11, 757, 1830, 3917, 9, 1431, 25, 7, 12, 3, 3887, 1159, 1744, 5, 5589, 79, 421, 1821, 8, 3, 4, 330, 17, 98, 3, 41, 7, 2, 673, 7, 12, 17, 16, 2, 17, 94, 4386, 48, 27, 2, 275, 11, 18, 2, 174, 6, 3163, 2, 85, 29, 3, 326, 6, 4541, 644, 19, 6, 3371, 94, 1778, 74, 2, 17, 2, 76, 6194, 673, 443, 3, 2, 6288, 7, 2, 28, 2, 84, 7, 2, 17, 27, 80, 4, 2229, 12126, 5, 24, 120, 38, 48, 11, 82, 8, 25, 10, 86, 44, 18, 2, 17, 16, 1285, 57, 4386, 151, 48, 113, 3, 23, 2, 139, 156, 6, 39, 10670, 2, 65, 12772, 117, 286, 5, 19, 76, 883, 4, 68, 17, 16, 24, 43, 557, 22, 175, 575, 6, 173, 2, 45]\n",
      "thing = [2, 83, 870, 5, 59, 471, 502, 13, 36, 31, 4, 17, 41, 167, 7, 677, 12, 3, 354, 26, 2385, 7192, 284, 642, 41, 2665, 1929, 116, 1628, 5, 26, 3942, 189, 7, 677, 11, 3, 1380, 16, 2, 7, 12, 13, 1713, 78, 133, 21, 196, 3, 678, 10, 192, 974, 1708, 9, 2, 581, 5, 56, 10, 41, 8, 6, 2, 84, 10, 3, 11, 8, 3, 76, 8, 3, 235, 4, 4, 351, 2, 358, 61, 4, 2750, 2, 621, 351, 16, 8, 3, 246, 19, 2, 76, 952, 156, 10, 197, 267, 12, 13, 3, 56, 2, 874, 30, 10, 93, 135, 2, 372, 16, 2, 84, 135, 62, 1273, 38, 44, 10, 3, 326, 6, 96, 210, 10, 121, 32, 12, 13, 3, 124, 6, 82, 120, 38, 2, 4103, 99, 1648, 11, 12, 16, 8, 421, 318, 5, 87, 548, 4, 1242]\n"
     ]
    }
   ],
   "source": [
    "for i, thing in enumerate(X_train_seq):\n",
    "    if i == 3:\n",
    "        break\n",
    "    print(\"thing = {}\".format(thing))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-12-03T23:53:40.925615Z",
     "iopub.status.busy": "2020-12-03T23:53:40.925355Z",
     "iopub.status.idle": "2020-12-03T23:53:40.929486Z",
     "shell.execute_reply": "2020-12-03T23:53:40.928715Z",
     "shell.execute_reply.started": "2020-12-03T23:53:40.925587Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(31807, 7779)\n"
     ]
    }
   ],
   "source": [
    "print(X_train_seq_pad.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-12-03T23:53:44.757097Z",
     "iopub.status.busy": "2020-12-03T23:53:44.756825Z",
     "iopub.status.idle": "2020-12-03T23:53:47.384784Z",
     "shell.execute_reply": "2020-12-03T23:53:47.384058Z",
     "shell.execute_reply.started": "2020-12-03T23:53:44.757068Z"
    }
   },
   "outputs": [],
   "source": [
    "#Convert to numpy arrays to work with Tensorflow\n",
    "X_train_seq_pad = np.array(X_train_seq_pad)\n",
    "y_train = np.array(y_train)\n",
    "\n",
    "X_test_seq_pad = np.array(X_test_seq_pad)\n",
    "y_test = np.array(y_test)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-12-03T23:53:50.583847Z",
     "iopub.status.busy": "2020-12-03T23:53:50.583542Z",
     "iopub.status.idle": "2020-12-03T23:53:50.588535Z",
     "shell.execute_reply": "2020-12-03T23:53:50.587973Z",
     "shell.execute_reply.started": "2020-12-03T23:53:50.583818Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((31807, 7779), (31807,))"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_seq_pad.shape, y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-12-03T23:53:53.798360Z",
     "iopub.status.busy": "2020-12-03T23:53:53.798091Z",
     "iopub.status.idle": "2020-12-03T23:53:53.802401Z",
     "shell.execute_reply": "2020-12-03T23:53:53.801853Z",
     "shell.execute_reply.started": "2020-12-03T23:53:53.798332Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((3535, 7779), (3535,))"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test_seq_pad.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-12-03T23:53:54.999107Z",
     "iopub.status.busy": "2020-12-03T23:53:54.998855Z",
     "iopub.status.idle": "2020-12-03T23:53:55.003937Z",
     "shell.execute_reply": "2020-12-03T23:53:55.003248Z",
     "shell.execute_reply.started": "2020-12-03T23:53:54.999079Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[   4,  445,  427, ...,    0,    0,    0],\n",
       "       [ 916,  545, 2785, ...,    0,    0,    0],\n",
       "       [  52,   69,  416, ...,    0,    0,    0]], dtype=int32)"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test_seq_pad[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-12-03T23:53:56.309133Z",
     "iopub.status.busy": "2020-12-03T23:53:56.308870Z",
     "iopub.status.idle": "2020-12-03T23:53:56.313380Z",
     "shell.execute_reply": "2020-12-03T23:53:56.312816Z",
     "shell.execute_reply.started": "2020-12-03T23:53:56.309105Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([7, 9, 5])"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train[:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-30T18:12:45.748845Z",
     "iopub.status.busy": "2020-11-30T18:12:45.748563Z",
     "iopub.status.idle": "2020-11-30T18:12:45.751628Z",
     "shell.execute_reply": "2020-11-30T18:12:45.750984Z",
     "shell.execute_reply.started": "2020-11-30T18:12:45.748814Z"
    }
   },
   "source": [
    "# Baseline Model\n",
    "The base line model is a custom word embedding providing vectorized words to two layers of 1-D convolutional next networks. According to Chollet a 1-D CNN model can (if properly tuned) do well at text classification.\n",
    "\n",
    "But the limitation is that if information in the text is highly dependend on the sequence of words, it will be limited. I think because sentiment in English can be highly determined not only by the words used but by the order in which they're used this model won't score well, but is a baseline of how well a simpler-to-train option could do.\n",
    "\n",
    "TODO: add Reference quoting Chollet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-12-04T00:43:55.252859Z",
     "iopub.status.busy": "2020-12-04T00:43:55.252579Z",
     "iopub.status.idle": "2020-12-04T00:43:55.356809Z",
     "shell.execute_reply": "2020-12-04T00:43:55.355837Z",
     "shell.execute_reply.started": "2020-12-04T00:43:55.252828Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_1 (Embedding)      (None, 7779, 64)          1216064   \n",
      "_________________________________________________________________\n",
      "conv1d_2 (Conv1D)            (None, 7773, 32)          14368     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_1 (MaxPooling1 (None, 1554, 32)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_3 (Conv1D)            (None, 1548, 32)          7200      \n",
      "_________________________________________________________________\n",
      "global_max_pooling1d_1 (Glob (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 15)                495       \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 15)                0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 10)                160       \n",
      "=================================================================\n",
      "Total params: 1,238,287\n",
      "Trainable params: 1,238,287\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#baseline_model = Sequential([\n",
    "#    Embedding(VOCAB_SIZE + 1,EMBEDDING_DIM, input_length=MAX_LENGTH),\n",
    "#    GlobalAveragePooling1D(),\n",
    "#    Dense(500, activation=\"relu\"),\n",
    "#    Dense(250, activation=\"relu\"),\n",
    "#    Dense(125, activation=\"relu\"),\n",
    "#    Dense(60, activation=\"relu\"),\n",
    "#    Dense(30, activation=\"relu\"),\n",
    "#    Dense(15, activation=\"relu\"),\n",
    "#    Dense(10, activation=\"softmax\")\n",
    "#])\n",
    "\n",
    "baseline_model = Sequential()\n",
    "baseline_model.add(Embedding(VOCAB_SIZE+1, EMBEDDING_DIM, input_length=Max_Length))\n",
    "baseline_model.add(Conv1D(32,7,activation=\"relu\"))\n",
    "baseline_model.add(MaxPooling1D(5))\n",
    "baseline_model.add(Conv1D(32,7,activation=\"relu\"))\n",
    "baseline_model.add(GlobalMaxPooling1D())\n",
    "baseline_model.add(Dense(15, activation=\"relu\", kernel_regularizer=regularizers.l2(0.001)))\n",
    "baseline_model.add(Dropout(0.2))\n",
    "baseline_model.add(Dense(10, activation=\"softmax\", kernel_regularizer=regularizers.l2(0.001)))\n",
    "\n",
    "baseline_model.compile(optimizer=\"adadelta\", loss=\"sparse_categorical_crossentropy\", metrics=[\"acc\"])\n",
    "baseline_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-12-04T00:45:18.782655Z",
     "iopub.status.busy": "2020-12-04T00:45:18.782364Z",
     "iopub.status.idle": "2020-12-04T00:45:18.787572Z",
     "shell.execute_reply": "2020-12-04T00:45:18.786815Z",
     "shell.execute_reply.started": "2020-12-04T00:45:18.782624Z"
    }
   },
   "outputs": [],
   "source": [
    "call_back_list = [\n",
    "    keras.callbacks.ModelCheckpoint(\n",
    "        filepath = \"../Data/baseline_model.h5\",\n",
    "        monitor = \"val_acc\",\n",
    "        save_best_only = True\n",
    "    ),\n",
    "    keras.callbacks.ReduceLROnPlateau(\n",
    "        monitor = \"val_acc\",\n",
    "        factor = 0.1,\n",
    "        patience = 3\n",
    "    ),\n",
    "    keras.callbacks.EarlyStopping(patience=15, verbose=1,restore_best_weights=True)\n",
    "    \n",
    "    \n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-12-04T00:45:18.788897Z",
     "iopub.status.busy": "2020-12-04T00:45:18.788694Z",
     "iopub.status.idle": "2020-12-04T00:58:18.952886Z",
     "shell.execute_reply": "2020-12-04T00:58:18.950961Z",
     "shell.execute_reply.started": "2020-12-04T00:45:18.788870Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "299/299 [==============================] - 28s 94ms/step - loss: 2.3245 - acc: 0.1056 - val_loss: 2.3229 - val_acc: 0.1179 - lr: 0.0010\n",
      "Epoch 2/100\n",
      "299/299 [==============================] - 28s 94ms/step - loss: 2.3232 - acc: 0.1074 - val_loss: 2.3220 - val_acc: 0.1195 - lr: 0.0010\n",
      "Epoch 3/100\n",
      "299/299 [==============================] - 28s 94ms/step - loss: 2.3228 - acc: 0.1089 - val_loss: 2.3211 - val_acc: 0.1220 - lr: 0.0010\n",
      "Epoch 4/100\n",
      "299/299 [==============================] - 28s 94ms/step - loss: 2.3221 - acc: 0.1115 - val_loss: 2.3202 - val_acc: 0.1254 - lr: 0.0010\n",
      "Epoch 5/100\n",
      "299/299 [==============================] - 28s 94ms/step - loss: 2.3208 - acc: 0.1134 - val_loss: 2.3193 - val_acc: 0.1267 - lr: 0.0010\n",
      "Epoch 6/100\n",
      "299/299 [==============================] - 28s 94ms/step - loss: 2.3198 - acc: 0.1177 - val_loss: 2.3184 - val_acc: 0.1298 - lr: 0.0010\n",
      "Epoch 7/100\n",
      "299/299 [==============================] - 28s 93ms/step - loss: 2.3189 - acc: 0.1205 - val_loss: 2.3175 - val_acc: 0.1345 - lr: 0.0010\n",
      "Epoch 8/100\n",
      "299/299 [==============================] - 28s 93ms/step - loss: 2.3178 - acc: 0.1213 - val_loss: 2.3167 - val_acc: 0.1374 - lr: 0.0010\n",
      "Epoch 9/100\n",
      "299/299 [==============================] - 28s 93ms/step - loss: 2.3167 - acc: 0.1228 - val_loss: 2.3158 - val_acc: 0.1412 - lr: 0.0010\n",
      "Epoch 10/100\n",
      "299/299 [==============================] - 28s 94ms/step - loss: 2.3166 - acc: 0.1262 - val_loss: 2.3150 - val_acc: 0.1434 - lr: 0.0010\n",
      "Epoch 11/100\n",
      "299/299 [==============================] - 28s 94ms/step - loss: 2.3152 - acc: 0.1300 - val_loss: 2.3141 - val_acc: 0.1487 - lr: 0.0010\n",
      "Epoch 12/100\n",
      "299/299 [==============================] - 28s 95ms/step - loss: 2.3141 - acc: 0.1331 - val_loss: 2.3133 - val_acc: 0.1531 - lr: 0.0010\n",
      "Epoch 13/100\n",
      "299/299 [==============================] - 28s 94ms/step - loss: 2.3133 - acc: 0.1337 - val_loss: 2.3125 - val_acc: 0.1531 - lr: 0.0010\n",
      "Epoch 14/100\n",
      "299/299 [==============================] - 28s 94ms/step - loss: 2.3126 - acc: 0.1360 - val_loss: 2.3116 - val_acc: 0.1522 - lr: 0.0010\n",
      "Epoch 15/100\n",
      "299/299 [==============================] - 28s 93ms/step - loss: 2.3113 - acc: 0.1403 - val_loss: 2.3108 - val_acc: 0.1468 - lr: 0.0010\n",
      "Epoch 16/100\n",
      "299/299 [==============================] - 28s 95ms/step - loss: 2.3119 - acc: 0.1396 - val_loss: 2.3107 - val_acc: 0.1462 - lr: 1.0000e-04\n",
      "Epoch 17/100\n",
      "299/299 [==============================] - 28s 94ms/step - loss: 2.3116 - acc: 0.1374 - val_loss: 2.3106 - val_acc: 0.1459 - lr: 1.0000e-04\n",
      "Epoch 18/100\n",
      "299/299 [==============================] - 28s 93ms/step - loss: 2.3111 - acc: 0.1387 - val_loss: 2.3105 - val_acc: 0.1456 - lr: 1.0000e-04\n",
      "Epoch 19/100\n",
      "299/299 [==============================] - 28s 95ms/step - loss: 2.3113 - acc: 0.1386 - val_loss: 2.3105 - val_acc: 0.1459 - lr: 1.0000e-05\n",
      "Epoch 20/100\n",
      "299/299 [==============================] - 28s 93ms/step - loss: 2.3109 - acc: 0.1408 - val_loss: 2.3105 - val_acc: 0.1459 - lr: 1.0000e-05\n",
      "Epoch 21/100\n",
      "299/299 [==============================] - 28s 94ms/step - loss: 2.3112 - acc: 0.1404 - val_loss: 2.3105 - val_acc: 0.1462 - lr: 1.0000e-05\n",
      "Epoch 22/100\n",
      "299/299 [==============================] - 28s 93ms/step - loss: 2.3111 - acc: 0.1382 - val_loss: 2.3105 - val_acc: 0.1462 - lr: 1.0000e-06\n",
      "Epoch 23/100\n",
      "299/299 [==============================] - 28s 94ms/step - loss: 2.3111 - acc: 0.1365 - val_loss: 2.3105 - val_acc: 0.1462 - lr: 1.0000e-06\n",
      "Epoch 24/100\n",
      "299/299 [==============================] - 28s 94ms/step - loss: 2.3109 - acc: 0.1424 - val_loss: 2.3105 - val_acc: 0.1462 - lr: 1.0000e-06\n",
      "Epoch 25/100\n",
      "299/299 [==============================] - 28s 93ms/step - loss: 2.3107 - acc: 0.1414 - val_loss: 2.3105 - val_acc: 0.1462 - lr: 1.0000e-07\n",
      "Epoch 26/100\n",
      "299/299 [==============================] - 28s 95ms/step - loss: 2.3110 - acc: 0.1419 - val_loss: 2.3105 - val_acc: 0.1462 - lr: 1.0000e-07\n",
      "Epoch 27/100\n",
      "299/299 [==============================] - 28s 93ms/step - loss: 2.3109 - acc: 0.1409 - val_loss: 2.3105 - val_acc: 0.1462 - lr: 1.0000e-07\n",
      "Epoch 28/100\n",
      "212/299 [====================>.........] - ETA: 7s - loss: 2.3118 - acc: 0.1390"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-74-2042e9ff8ae8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m training_history = baseline_model.fit(X_train_seq_pad,\n\u001b[0m\u001b[1;32m      2\u001b[0m                                       \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m                                       \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mEPOCHS\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m                                       \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mBATCH_SIZE\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m                                       \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcall_back_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3_2020_07/envs/project5_venv/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     64\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_method_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_in_multi_worker_mode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 66\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     67\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m     \u001b[0;31m# Running inside `run_distribute_coordinator` already.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3_2020_07/envs/project5_venv/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m    846\u001b[0m                 batch_size=batch_size):\n\u001b[1;32m    847\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 848\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    849\u001b[0m               \u001b[0;31m# Catch OutOfRangeError for Datasets of unknown size.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    850\u001b[0m               \u001b[0;31m# This blocks until the batch has finished executing.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3_2020_07/envs/project5_venv/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    578\u001b[0m         \u001b[0mxla_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mExit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    579\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 580\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    581\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    582\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mtracing_count\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3_2020_07/envs/project5_venv/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    609\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    610\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 611\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    612\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    613\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3_2020_07/envs/project5_venv/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2418\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2419\u001b[0m       \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2420\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2421\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2422\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3_2020_07/envs/project5_venv/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_filtered_call\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m   1659\u001b[0m       \u001b[0;31m`\u001b[0m\u001b[0margs\u001b[0m\u001b[0;31m`\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1660\u001b[0m     \"\"\"\n\u001b[0;32m-> 1661\u001b[0;31m     return self._call_flat(\n\u001b[0m\u001b[1;32m   1662\u001b[0m         (t for t in nest.flatten((args, kwargs), expand_composites=True)\n\u001b[1;32m   1663\u001b[0m          if isinstance(t, (ops.Tensor,\n",
      "\u001b[0;32m~/anaconda3_2020_07/envs/project5_venv/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1743\u001b[0m         and executing_eagerly):\n\u001b[1;32m   1744\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1745\u001b[0;31m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0m\u001b[1;32m   1746\u001b[0m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[1;32m   1747\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n",
      "\u001b[0;32m~/anaconda3_2020_07/envs/project5_venv/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    591\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0m_InterpolateFunctionError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    592\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcancellation_manager\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 593\u001b[0;31m           outputs = execute.execute(\n\u001b[0m\u001b[1;32m    594\u001b[0m               \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    595\u001b[0m               \u001b[0mnum_outputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_outputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3_2020_07/envs/project5_venv/lib/python3.8/site-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     57\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 59\u001b[0;31m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[1;32m     60\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "training_history = baseline_model.fit(X_train_seq_pad,\n",
    "                                      y_train,\n",
    "                                      epochs=EPOCHS,\n",
    "                                      batch_size=BATCH_SIZE,\n",
    "                                      callbacks=call_back_list,\n",
    "                                      validation_split=Test_Size, \n",
    "                                      verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2020-12-04T00:58:18.954163Z",
     "iopub.status.idle": "2020-12-04T00:58:18.954529Z"
    }
   },
   "outputs": [],
   "source": [
    "loss = training_history.history[\"loss\"]\n",
    "val_loss = training_history.history[\"val_loss\"]\n",
    "acc = training_history.history[\"acc\"]\n",
    "val_acc = training_history.history[\"val_acc\"]\n",
    "epochs = range(1,len(loss)+1)\n",
    "\n",
    "plt.figure(figsize=(20,20))\n",
    "plt.plot(epochs, loss,\"bo\",label=\"Training Loss\")\n",
    "plt.plot(epochs, val_loss,\"b\",label=\"Validation Loss\")\n",
    "\n",
    "plt.legend()\n",
    "#plt.show()\n",
    "plt.savefig(\"../Documents/Images/loss_curves.png\",dpi=400)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2020-12-04T00:58:18.955537Z",
     "iopub.status.idle": "2020-12-04T00:58:18.955865Z"
    }
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20,20))\n",
    "plt.plot(epochs, acc,\"go\",label=\"Training Acc\")\n",
    "plt.plot(epochs, val_acc,\"g\",label=\"Validation Acc\")\n",
    "plt.legend()\n",
    "#plt.show()\n",
    "plt.savefig(\"../Documents/Images/accuracy_curves.png\",dpi=400)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Huge overfit!\n",
    "\n",
    "Things I need to try:\n",
    "\n",
    "* Collect more data\n",
    "* Use a pretrained word embedding\n",
    "* Regularize\n",
    "* Add callbacks to make training work harder for me\n",
    "* which should I use as a loss function: `sparse_categorical_crossentropy` or `categorical_crossentropy`\n",
    "* Which optimizer should I use: `adam` or `RMSprop(lr=0.1)`\n",
    "\n",
    "**TODO**:\n",
    "Find out what it means when val_loss improves by val_acc does not improve.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2020-12-04T00:58:18.956758Z",
     "iopub.status.idle": "2020-12-04T00:58:18.957085Z"
    }
   },
   "outputs": [],
   "source": [
    "score, acc = baseline_model.evaluate(X_test_seq_pad, y_test, batch_size=BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2020-12-04T00:58:18.958053Z",
     "iopub.status.idle": "2020-12-04T00:58:18.958376Z"
    }
   },
   "outputs": [],
   "source": [
    "print(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2020-12-04T00:58:18.959319Z",
     "iopub.status.idle": "2020-12-04T00:58:18.959616Z"
    }
   },
   "outputs": [],
   "source": [
    "print(acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2020-12-04T00:58:18.960387Z",
     "iopub.status.idle": "2020-12-04T00:58:18.960610Z"
    }
   },
   "outputs": [],
   "source": [
    "#TODO Add F1, "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-30T18:13:50.940607Z",
     "iopub.status.busy": "2020-11-30T18:13:50.940360Z",
     "iopub.status.idle": "2020-11-30T18:13:50.943187Z",
     "shell.execute_reply": "2020-11-30T18:13:50.942548Z",
     "shell.execute_reply.started": "2020-11-30T18:13:50.940580Z"
    }
   },
   "source": [
    "# Updated Model\n",
    "Will have a model with the following features:\n",
    "\n",
    "* Pretrained word embedding\n",
    "* LSTM (or GRU)\n",
    "* Possibliy bidirectional\n",
    "* More regularization\n",
    "* If training is too long: Opt for GRU. Also may opt for a CNN+RNN hybrid\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pretrained Word Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-12-04T00:58:27.188001Z",
     "iopub.status.busy": "2020-12-04T00:58:27.187661Z",
     "iopub.status.idle": "2020-12-04T01:05:14.546615Z",
     "shell.execute_reply": "2020-12-04T01:05:14.545748Z",
     "shell.execute_reply.started": "2020-12-04T00:58:27.187967Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2020-12-03 16:58:27--  http://nlp.stanford.edu/data/glove.6B.zip\n",
      "Resolving nlp.stanford.edu (nlp.stanford.edu)... 171.64.67.140\n",
      "Connecting to nlp.stanford.edu (nlp.stanford.edu)|171.64.67.140|:80... connected.\n",
      "HTTP request sent, awaiting response... 302 Found\n",
      "Location: https://nlp.stanford.edu/data/glove.6B.zip [following]\n",
      "--2020-12-03 16:58:27--  https://nlp.stanford.edu/data/glove.6B.zip\n",
      "Connecting to nlp.stanford.edu (nlp.stanford.edu)|171.64.67.140|:443... connected.\n",
      "HTTP request sent, awaiting response... 301 Moved Permanently\n",
      "Location: http://downloads.cs.stanford.edu/nlp/data/glove.6B.zip [following]\n",
      "--2020-12-03 16:58:27--  http://downloads.cs.stanford.edu/nlp/data/glove.6B.zip\n",
      "Resolving downloads.cs.stanford.edu (downloads.cs.stanford.edu)... 171.64.64.22\n",
      "Connecting to downloads.cs.stanford.edu (downloads.cs.stanford.edu)|171.64.64.22|:80... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 862182613 (822M) [application/zip]\n",
      "Saving to: ../Data/glove.6B.zip\n",
      "\n",
      "../Data/glove.6B.zi 100%[===================>] 822.24M  1.88MB/s    in 6m 28s  \n",
      "\n",
      "2020-12-03 17:04:55 (2.12 MB/s) - ../Data/glove.6B.zip saved [862182613/862182613]\n",
      "\n",
      "Archive:  ../Data/glove.6B.zip\n",
      "  inflating: ../Data/glove.6B.50d.txt  \n",
      "  inflating: ../Data/glove.6B.100d.txt  \n",
      "  inflating: ../Data/glove.6B.200d.txt  \n",
      "  inflating: ../Data/glove.6B.300d.txt  \n"
     ]
    }
   ],
   "source": [
    "!./get_word_vectors.sh\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-12-04T01:44:23.826305Z",
     "iopub.status.busy": "2020-12-04T01:44:23.826018Z",
     "iopub.status.idle": "2020-12-04T01:44:48.643464Z",
     "shell.execute_reply": "2020-12-04T01:44:48.642586Z",
     "shell.execute_reply.started": "2020-12-04T01:44:23.826273Z"
    }
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "could not broadcast input array from shape (300) into shape (64)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-80-854c0fca9466>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0membedding_vector\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m         \u001b[0mEmbedding_Matrix\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindex_value\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0membedding_vector\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: could not broadcast input array from shape (300) into shape (64)"
     ]
    }
   ],
   "source": [
    "#build embedding matrix\n",
    "\n",
    "word_index = tokenizer.word_index\n",
    "\n",
    "embedding_dict = {}\n",
    "\n",
    "GLOVE6B300_FILE = open(\"../Data/glove.6B.300d.txt\",\"r\")\n",
    "\n",
    "for line in GLOVE6B300_FILE:\n",
    "    line_values = line.split(\" \")\n",
    "    word = line_values[0]\n",
    "    vector_components = np.asarray(line_values[1:], dtype=\"float32\")\n",
    "    embedding_dict[word] = vector_components\n",
    "\n",
    "Embedding_Matrix = np.zeros((VOCAB_SIZE + 1, EMBEDDING_DIM))\n",
    "\n",
    "for word, index_value in word_index.items():\n",
    "    embedding_vector = embedding_dict.get(word)\n",
    "    \n",
    "    if embedding_vector is not None:\n",
    "        Embedding_Matrix[index_value] = embedding_vector\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-30T18:13:54.540365Z",
     "iopub.status.busy": "2020-11-30T18:13:54.540109Z",
     "iopub.status.idle": "2020-11-30T18:13:54.542941Z",
     "shell.execute_reply": "2020-11-30T18:13:54.542361Z",
     "shell.execute_reply.started": "2020-11-30T18:13:54.540337Z"
    }
   },
   "source": [
    "# Conclusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
