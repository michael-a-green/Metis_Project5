import os

#uncomment this if you want to run on your GPU instead of CPU
os.environ["CUDA_DEVICE_ORDER"] = "PCI_BUS_ID" 
os.environ["CUDA_VISIBLE_DEVICES"] = ""

import datetime
from collections import Counter
import re

import pickle
import pandas as pd
import numpy as np

import nltk
from nltk.corpus import words as nltk_words
from nltk.corpus import wordnet
from nltk.tag import pos_tag
from nltk.tokenize import word_tokenize
from nltk.stem import WordNetLemmatizer
from nltk.corpus import stopwords

import tensorflow
from tensorflow import keras
from tensorflow.keras.preprocessing.sequence import pad_sequences
from tensorflow.keras.layers import Embedding, LSTM, Dense, GRU
from tensorflow.keras.layers import Dense, Dropout, Bidirectional
from tensorflow.keras.layers import GlobalAveragePooling1D, Flatten, Conv1D
from tensorflow.keras.layers import MaxPooling1D, GlobalMaxPooling1D

from tensorflow.keras.preprocessing.text import Tokenizer
from tensorflow.keras.models import Sequential
from tensorflow.keras.optimizers import Adam
from tensorflow.keras import regularizers
from tensorflow.keras.utils import plot_model

import tensorflow.keras.utils as ku

from tensorflow.keras.models import load_model

#Common constants


#CONSTANTS_FILE = open(constants_file_name,"rb")

#[TRUC_TYPE, PAD_TYPE, OOV_TOK, Max_Length] = pickle.load(CONSTANTS_FILE)

class MyClassifier:

    def __init__(self):
        model_arch_weights_name = os.getenv("MODEL_ARCH_WEIGHTS")
        tokenizer_file_name = os.getenv("TOKENIZER_FILE")
        constants_file_name = os.getenv("CONSTANT_FILE_NAME")

        self.model = load_model(model_arch_weights_name)
        #do I have to do this?
        #self.model._make_predict_function()
        self.wordNetLemmatizer = WordNetLemmatizer()
        self.TOKENIZER_FILE = open(tokenizer_file_name,"rb")
        self.tokenizer = pickle.load(self.TOKENIZER_FILE)
        self.CONSTANTS_FILE = open(constants_file_name,"rb")
        [self.TRUC_TYPE, self.PAD_TYPE, self.OOV_TOK, self.Max_Length] = pickle.load(self.CONSTANTS_FILE)
        
        if self.model == None:
            print("Error predictor did not load properly!")


    def remove_html_punct(self, row):
        """This function removes HTML and punctuation and anything that is or contains a number from the Text"""

        NLTK_WORDS = set(nltk_words.words())

        text_to_process = row["review_text"]
        text_to_process = text_to_process.lower()
        text_to_process = re.sub("<.*?>","",text_to_process)
        text_to_process = re.sub("[\.|\!|\?|\,|\;|\:|\&|\(|\)|\-|\%|_|\#|\$|\*|\+|\/|\=|\[|\]|\^|\`|\{|\}|\~]","",text_to_process)
        text_to_process = re.sub("\w*\d+\w*","",text_to_process)
        text_to_process_list = text_to_process.split()
        text_to_process_list = [review_word for review_word in text_to_process_list if review_word in NLTK_WORDS]
        text_to_process = " ".join(text_to_process_list)
        return text_to_process

    def tokenize_text(self, row):
        temp_tokenized_txt = word_tokenize(row["review_text"])
        return temp_tokenized_txt

    def calc_partofspeech(self,raw_pos):
        """translates from POS generated by pos_tag() to a POS encoding that WordNetLemmatizer.lemmatize() understands"""
        #print("word = ",word)
        #[(output_word, output_pos)] = pos_tag(word_tokenize(word))
    
        #decode output_pos to the pos required by the lemmatizer
    
        if "JJ" in raw_pos:
            pos = "a"
        elif "RB" in raw_pos:
            pos = "r"
        elif "VB" in raw_pos:
            pos = "v"
        else:
            pos = "n"
    
        return pos

    def lemmatize_it(self,row):

        pos_result = pos_tag(row["review_text"])

        temp_mydoc_lemmatized = []

        for myword,myPOS in pos_result:
            temp_word_lemmatized = self.wordNetLemmatizer.lemmatize(myword,self.calc_partofspeech(myPOS))
            temp_mydoc_lemmatized.append(temp_word_lemmatized)

        return temp_mydoc_lemmatized

    def gen_net_promoter(self,star_rating):
        """
        Converts 1-10 / 10 star ranking to a 1-3/3 net promoter score
        Only works on a single-row data frame
        """
        if star_rating <= 6:
            #Detractor
            return 0
        elif star_rating <= 8:
            #Passive
            return 1
        else:
            ##Promotor
            return 2
        
    def predict(self, data_df):
        """
        takes data_df which is expected to be a pandas data frame with the same format as 
        text_of_reviews in Project5.ipynb
        and returns a predicted NPS score for the text field
    
        """
        
        #data_df["review_observation"] = data_df["review_title"].to_string(index=False) + " " + data_df["review_text"].to_string(index=False)
        data_df["review_observation"] = data_df["review_title"] + " " + data_df["review_text"]
       
        data_df = data_df.rename(columns={"review_text":"review_text_original"})
        data_df = data_df.rename(columns= {"review_observation":"review_text"})
        data_df["review_text"] = data_df.apply(self.remove_html_punct, axis=1)
        data_df["review_text"] = data_df.apply(self.tokenize_text, axis=1)
        data_df["review_text"] = data_df.apply(self.lemmatize_it, axis=1)
        data_df["review_text"] = data_df.apply(lambda x : " ".join(x["review_text"]), axis=1)
        #cheating - just doing a direct conversion
        #data_df["net_promoter_score"] = data_df.review_star_rating.apply(self.gen_net_promoter)

        #tokenizer has already been fit so no need to do it again
        X_train = data_df["review_text"]
        X_train = np.array(X_train)
        X_train_seq = self.tokenizer.texts_to_sequences(X_train)
        X_train_seq_pad = pad_sequences(X_train_seq, maxlen=self.Max_Length, padding=self.PAD_TYPE, truncating=self.TRUC_TYPE)
        y_pred = self.model.predict(X_train_seq_pad)
        y_pred = [np.argmax(y_thing) for y_thing in y_pred]
        y_pred = y_pred[0]
        return y_pred

        
################################
# Test code
################################
if __name__ == "__main__":
    mything = {"review_text" : ["This movie was terrible"], "review_title" : ["The worst"], "review_star_rating" : [1] }
    mything_df = pd.DataFrame(mything)
    apredictor = MyClassifier()
    y_pred = apredictor.predict(mything_df)
    
    #returns a pandas series
    y_test = mything_df.review_star_rating.apply( apredictor.gen_net_promoter  )
    #getting scalar out of pandas series
    y_test = y_test[0]
    y_test = y_test
    
    print("review title = {}\nreview text =\n{}\nactual = {}\npredicted = {} \n".format(
        mything_df.loc[0, "review_title"],
        mything_df.loc[0, "review_text"],
        y_test,
        y_pred)
    )

    assert (y_pred == y_test)
    
    mything = {"review_text" : ["This movie was very good"], "review_title" : ["The best"], "review_star_rating" : [9] }
    mything_df = pd.DataFrame(mything)
    y_pred = apredictor.predict(mything_df)
    
    y_test = mything_df.review_star_rating.apply( apredictor.gen_net_promoter  )
    y_test = y_test[0]
    
    print("review title = {}\nreview text =\n{}\nactual = {}\npredicted = {} \n".format(
        mything_df.loc[0, "review_title"],
        mything_df.loc[0, "review_text"],
        y_test,
        y_pred)
    )
    assert (y_pred == y_test)


    
    
       
