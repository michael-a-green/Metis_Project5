import os

#uncomment this if you want to run on your CPU instead of GPU
#os.environ["CUDA_DEVICE_ORDER"] = "PCI_BUS_ID" 
#os.environ["CUDA_VISIBLE_DEVICES"] = ""

import datetime
from collections import Counter
import re

import pickle
import pandas as pd
import numpy as np

import nltk
from nltk.corpus import words as nltk_words
from nltk.corpus import wordnet
from nltk.tag import pos_tag
from nltk.tokenize import word_tokenize
from nltk.stem import WordNetLemmatizer
from nltk.corpus import stopwords

import tensorflow
from tensorflow import keras
from tensorflow.keras.preprocessing.sequence import pad_sequences
from tensorflow.keras.layers import Embedding, LSTM, Dense, GRU
from tensorflow.keras.layers import Dense, Dropout, Bidirectional
from tensorflow.keras.layers import GlobalAveragePooling1D, Flatten, Conv1D
from tensorflow.keras.layers import MaxPooling1D, GlobalMaxPooling1D

from tensorflow.keras.preprocessing.text import Tokenizer
from tensorflow.keras.models import Sequential
from tensorflow.keras.optimizers import Adam
from tensorflow.keras import regularizers
from tensorflow.keras.utils import plot_model

import tensorflow.keras.utils as ku

from tensorflow.keras.models import load_model

#Common constants
CONSTANTS_FILE = open("../../../Data/constants.pkl","rb")

[TRUC_TYPE, PAD_TYPE, OOV_TOK, Max_Length] = pickle.load(CONSTANTS_FILE)

class MyPredictor:

    def __init__(self):
        self.model = load_model("../../../Data/updated_model2_arch_weights")
        self.wordNetLemmatizer = WordNetLemmatizer()    
        if self.model == None:
            print("Error predictor did not load properly!")


    def remove_html_punct(self, row):
        """This function removes HTML and punctuation and anything that is or contains a number from the Text"""

        NLTK_WORDS = set(nltk_words.words())

        text_to_process = row["review_text"]
        text_to_process = text_to_process.lower()
        text_to_process = re.sub("<.*?>","",text_to_process)
        text_to_process = re.sub("[\.|\!|\?|\,|\;|\:|\&|\(|\)|\-|\%|_|\#|\$|\*|\+|\/|\=|\[|\]|\^|\`|\{|\}|\~]","",text_to_process)
        text_to_process = re.sub("\w*\d+\w*","",text_to_process)
        text_to_process_list = text_to_process.split()
        text_to_process_list = [review_word for review_word in text_to_process_list if review_word in NLTK_WORDS]
        text_to_process = " ".join(text_to_process_list)
        return text_to_process

    def tokenize_text(self, row):
        temp_tokenized_txt = word_tokenize(row["review_text"])
        return temp_tokenized_txt

    def calc_partofspeech(self,raw_pos):
        """translates from POS generated by pos_tag() to a POS encoding that WordNetLemmatizer.lemmatize() understands"""
        #print("word = ",word)
        #[(output_word, output_pos)] = pos_tag(word_tokenize(word))
    
        #decode output_pos to the pos required by the lemmatizer
    
        if "JJ" in raw_pos:
            pos = "a"
        elif "RB" in raw_pos:
            pos = "r"
        elif "VB" in raw_pos:
            pos = "v"
        else:
            pos = "n"
    
        return pos

    def lemmatize_it(self,row):

        pos_result = pos_tag(row["review_text"])

        temp_mydoc_lemmatized = []

        for myword,myPOS in pos_result:
            temp_word_lemmatized = self.wordNetLemmatizer.lemmatize(myword,self.calc_partofspeech(myPOS))
            temp_mydoc_lemmatized.append(temp_word_lemmatized)

        return temp_mydoc_lemmatized

    def gen_net_promoter(self,row):
        if row["review_star_rating"] <= 5:
            #Detractor
            return 0
        elif row["review_star_rating"] <= 8:
            #Passive
            return 1
        else:
            ##Promotor
            return 2
        
    def predict(self, data_df):
        """
        takes data_df which is expected to be a pandas data frame with the same format as 
        text_of_reviews in Project5.ipynb
        and returns a predicted NPS score for the text field
    
        """
        
        #data_df["review_observation"] = data_df["review_title"].to_string(index=False) + " " + data_df["review_text"].to_string(index=False)
        data_df["review_observation"] = data_df["review_title"] + " " + data_df["review_text"]
       
        data_df = data_df.rename(columns={"review_text":"review_text_original"})
        data_df = data_df.rename(columns= {"review_observation":"review_text"})
        data_df["review_text"] = data_df.apply(self.remove_html_punct, axis=1)
        data_df["review_text"] = data_df.apply(self.tokenize_text, axis=1)
        data_df["review_text"] = data_df.apply(self.lemmatize_it, axis=1)
        data_df["review_text"] = data_df.apply(lambda x : " ".join(x["review_text"]), axis=1)
        #cheating - just doing a direct conversion
        data_df["net_promoter_score"] = data_df.apply(self.gen_net_promoter, axis=1)


if __name__ == "__main__":
    mything = {"review_text" : ["This movie was terrible"], "review_title" : ["The worst"], "review_star_rating" : [1] }
    mything_df = pd.DataFrame(mything)
    apredictor = MyPredictor()
    apredictor.predict(mything_df)


    
    
       
